{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9953d4b-091a-497f-9e14-ba0dd4017083",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to compute the **vertical geomagnetic cutoff rigidity** at a given geographic location by backtracing charged particles through the geomagnetic field.\n",
    "\n",
    "The key idea is to perform **backtracing** of charged particles in a realistic geomagnetic field model (IGRF). For a given geographic location and a set of trial rigidities, each trajectory is classified as:\n",
    "- **allowed** (the particle can reach the location from outside the magnetosphere), or\n",
    "- **forbidden** (the particle is blocked/trapped and does not reach the location from outside).\n",
    "\n",
    "This allowed/forbidden pattern as a function of rigidity is often called a **cutoff barcode**, and the transition region is the **penumbra**.\n",
    "\n",
    "Workflow overview:\n",
    "- Define the magnetospheric magnetic field model (IGRF) and basic simulation parameters.\n",
    "- For a grid of rigidities, launch *backtraced* trajectories and classify them as “allowed” or “forbidden” based on the exit/termination condition (a rigidity “barcode”).\n",
    "- Derive penumbra parameters from the barcode: `R_min`, `R_eff`, `R_max`.\n",
    "- Build a global map of effective cutoff rigidity using a coarse scan and then refine it locally.\n",
    "\n",
    "Expected output:\n",
    "- A barcode (allowed/forbidden vs rigidity) for a chosen point (Moscow in this example), with values of `R_min`, `R_eff`, `R_max` in GV.\n",
    "- A coarse and a refined world map of `R_eff` on a latitude/longitude grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd5faf0-802a-4abd-a66a-4bad8e13f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gtsimulation.Algos import BunemanBorisSimulator\n",
    "from gtsimulation.Global import Regions, Units\n",
    "from gtsimulation.MagneticFields.Magnetosphere import Gauss\n",
    "from gtsimulation.Particle import Generators, Flux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b428d1bc-16b0-40de-8aae-87c372901fde",
   "metadata": {},
   "source": [
    "# Simulation settings: field model and integration parameters\n",
    "\n",
    "Here we define the global simulation configuration used throughout the notebook:\n",
    "- date and region settings for the magnetospheric field model,\n",
    "- the IGRF model configuration (core field, specific version),\n",
    "- integration time step and total integration time,\n",
    "- geometric break conditions (e.g., stop when reaching `R_min` or `R_max`),\n",
    "- output settings (`save`) to store only the trajectory coordinates (to keep outputs lightweight).\n",
    "\n",
    "Expected outcome: a consistent setup that can be reused to compute a rigidity “barcode” for many rigidities and locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d04c0-c118-4272-ac52-5b221fcd6523",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime(2025, 1, 1)\n",
    "region = Regions.Magnetosphere\n",
    "b_field = Gauss(model=\"IGRF\", version=14, model_type=\"core\", date=date)\n",
    "medium = None\n",
    "\n",
    "use_decay = False\n",
    "nuclear_interaction = None\n",
    "\n",
    "total_time = 5  # total time [s]\n",
    "dt = 1e-3  # time step [s]\n",
    "n_steps = int(total_time / dt)\n",
    "break_conditions = {\"Rmin\": 1 * Units.RE, \"Rmax\": 30 * Units.RE}\n",
    "\n",
    "save = [1, {\"Coordinates\": True, \"Velocities\": False}]\n",
    "output = None\n",
    "\n",
    "verbose = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4256d552-03cc-4451-8052-4914301df5a5",
   "metadata": {},
   "source": [
    "# Vertical rigidity barcode for a single location (Moscow example)\n",
    "\n",
    "This section computes a **vertical cutoff barcode** for a chosen site:\n",
    "- convert geodetic coordinates (lon/lat/alt) to geocentric Cartesian coordinates,\n",
    "- build a set of particles with different rigidities but identical initial position and vertical direction,\n",
    "- backtrace trajectories and label each rigidity as “allowed” or “forbidden” based on the termination code.\n",
    "\n",
    "Expected output:\n",
    "- a boolean array (barcode) over rigidity,\n",
    "- numerical estimates of `R_min`, `R_eff`, `R_max`,\n",
    "- a 1D barcode plot with these values marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3eefa4-0a14-433a-b7a9-5133e150b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Transformer\n",
    "\n",
    "lla_to_geo = Transformer.from_crs(\n",
    "    {\"proj\": \"longlat\", \"ellps\": \"WGS84\"},\n",
    "    {\"proj\": \"geocent\", \"ellps\": \"WGS84\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa3fb32-719e-4e88-9a5f-5df5e1bd8b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vertical_barcode(lon, lat, alt, rigidity_array):\n",
    "    r = lla_to_geo.transform(lon, lat, alt * 1e3, radians=False)\n",
    "    v = np.array([\n",
    "        np.cos(np.deg2rad(lon)) * np.cos(np.deg2rad(lat)),\n",
    "        np.sin(np.deg2rad(lon)) * np.cos(np.deg2rad(lat)),\n",
    "        np.sin(np.deg2rad(lat))\n",
    "    ])\n",
    "    energy_array = np.sqrt((rigidity_array * 1e3) ** 2 + 938.7 ** 2) - 938.7\n",
    "    particle = Flux(\n",
    "        Spectrum=Generators.Spectrums.UserInput(energy=energy_array * Units.MeV),\n",
    "        Distribution=Generators.Distributions.UserInput(\n",
    "            R0=np.tile(r, (rigidity_array.size, 1)),\n",
    "            V0=np.tile(v, (rigidity_array.size, 1))\n",
    "        ),\n",
    "        Names=\"anti_proton\",\n",
    "        Nevents=rigidity_array.size\n",
    "    )\n",
    "    simulator = BunemanBorisSimulator(\n",
    "        Bfield=b_field,\n",
    "        Region=region,\n",
    "        Medium=medium,\n",
    "        Particles=particle,\n",
    "        InteractNUC=nuclear_interaction,\n",
    "        UseDecay=use_decay,\n",
    "        Date=date,\n",
    "        Step=dt,\n",
    "        Num=n_steps,\n",
    "        BreakCondition=break_conditions,\n",
    "        Save=save,\n",
    "        Output=output,\n",
    "        Verbose=verbose\n",
    "    )\n",
    "    track_list = simulator()[0]\n",
    "    barcode = np.array([track[\"BC\"][\"WOut\"] == 8 for track in track_list])\n",
    "    return barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f8ac71-a689-42c3-afc7-470256ed77db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rigidity_array = np.arange(1.6, 2.801, 0.002)\n",
    "barcode = get_vertical_barcode(37.32, 55.47, 20, rigidity_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a50cc9-78cd-490d-8f25-eca743254c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_edges_from_centers(x):\n",
    "    e = np.empty(x.size + 1, dtype=x.dtype)\n",
    "    e[1:-1] = (x[:-1] + x[1:]) / 2\n",
    "    e[0] = x[0] - (x[1] - x[0]) / 2\n",
    "    e[-1] = x[-1] + (x[-1] - x[-2]) / 2\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abfe292-3a52-4259-8ea3-8497083b98e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_penumbra_parameters(rigidity_array, barcode):\n",
    "    rigidity_edges = bin_edges_from_centers(rigidity_array)\n",
    "\n",
    "    if np.all(barcode):\n",
    "        return rigidity_edges[0], rigidity_edges[0], rigidity_edges[0]\n",
    "\n",
    "    if np.all(~barcode):\n",
    "        return rigidity_edges[-1], rigidity_edges[-1], rigidity_edges[-1]\n",
    "\n",
    "    idx_true = np.flatnonzero(barcode)\n",
    "    i_min = idx_true[0]\n",
    "    r_min = rigidity_edges[i_min]\n",
    "\n",
    "    idx_false = np.flatnonzero(~barcode)\n",
    "    i_max = idx_false[-1]\n",
    "    r_max = rigidity_edges[i_max + 1]\n",
    "\n",
    "    widths = rigidity_edges[i_min + 1 : i_max + 2] - rigidity_edges[i_min : i_max + 1]\n",
    "    allowed_width = widths[barcode[i_min : i_max + 1]].sum()\n",
    "    r_eff = r_max - allowed_width\n",
    "\n",
    "    return r_min, r_eff, r_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a521df5-83fb-4a68-aa1f-2bdb8271b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_min, r_eff, r_max = get_penumbra_parameters(rigidity_array, barcode)\n",
    "print('R_min =', r_min, 'GV')\n",
    "print('R_eff =', r_eff, 'GV')\n",
    "print('R_max =', r_max, 'GV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab4556-b7fb-4258-b7b4-026153a894e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 1))\n",
    "ax = fig.subplots()\n",
    "\n",
    "rigidity_edges = bin_edges_from_centers(rigidity_array)\n",
    "ax.pcolormesh(rigidity_edges, np.array([0, 1]), np.array(barcode)[np.newaxis, :], cmap='binary_r', vmin=0, vmax=1)\n",
    "ax.plot([r_min, r_min], [0, 1], 'r')\n",
    "ax.plot([r_max, r_max], [0, 1], 'r')\n",
    "ax.plot([r_eff, r_eff], [0, 1], 'b')\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel('Rigidity [GV]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a6136-a13f-4de3-b9a6-426d154298ce",
   "metadata": {},
   "source": [
    "# Effective cutoff rigidity map (global scan)\n",
    "\n",
    "This part demonstrates how to build a global map of the **effective vertical cutoff rigidity** `R_eff`:\n",
    "- define a latitude/longitude grid,\n",
    "- compute the barcode and `R_eff` at each grid node,\n",
    "- visualize results on a world map projection.\n",
    "\n",
    "Expected output: a world map of `R_eff` (in GV), showing higher cutoffs near the equator and lower cutoffs toward the poles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205956dd-80f1-4739-b4af-b46de9220a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install joblib tqdm_joblib cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9e0b37-9c77-4d20-928c-11f211c160fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm_joblib import tqdm_joblib\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b6c0d6-bae2-45d6-9560-610aa9caa4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_grid = np.arange(-180, 161, 20)\n",
    "lat_grid = np.arange(-70, 71, 10)\n",
    "\n",
    "r_grid = np.empty((lat_grid.size, lon_grid.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e64f75-881e-4c97-a82b-0d248420edac",
   "metadata": {},
   "source": [
    "# Coarse map: fast scan on a wide rigidity grid\n",
    "\n",
    "To get a quick global overview, we compute `R_eff` on a coarse rigidity grid (here 0.5 GV step).\n",
    "With such a step, fine penumbra structure is typically not resolved, but the result is sufficient to estimate typical cutoff levels at different locations.\n",
    "\n",
    "To reduce runtime, the computation is parallelized over grid points.\n",
    "Expected output: a coarse global map of `R_eff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8584ce5a-0daf-4527-a85e-8ba50f7cf47f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rigidity_array = np.arange(0.5, 19.51, 0.5)\n",
    "def worker(i_lon, i_lat):\n",
    "    barcode = get_vertical_barcode(lon_grid[i_lon], lat_grid[i_lat], 400, rigidity_array)\n",
    "    _, r_eff, _ = get_penumbra_parameters(rigidity_array, barcode)\n",
    "    return i_lon, i_lat, r_eff\n",
    "\n",
    "tasks = [(i, j) for i in range(lon_grid.size) for j in range(lat_grid.size)]\n",
    "with tqdm_joblib(total=len(tasks)):\n",
    "    res = Parallel(n_jobs=-1)(delayed(worker)(i, j) for i, j in tasks)\n",
    "for i_lon, i_lat, v in res:\n",
    "    r_grid[i_lat, i_lon] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9d01b-3763-4503-b2c5-7f0e9a75212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the 180° meridian and copy values from the -180° meridian in order to stitch the map seamlessly\n",
    "lon_grid = np.hstack((lon_grid, 180))\n",
    "r_grid = np.pad(r_grid, pad_width=((0, 0), (0, 1)), mode=\"wrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a552ae09-ad2c-4367-ba0d-3a77b633ef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "pcm = ax.pcolormesh(lon_grid, lat_grid, r_grid, vmin=0)\n",
    "ax.set_xlim(-180, 180)\n",
    "ax.set_ylim(-70, 70)\n",
    "ax.coastlines(resolution=\"110m\", linewidth=1.0, color=\"black\")\n",
    "\n",
    "ax.set_xticks(np.arange(-180, 181, 60))\n",
    "ax.set_yticks(np.arange(-60, 61, 20))\n",
    "ax.set_xlabel('Longitude [deg]')\n",
    "ax.set_ylabel('Latitude [deg]')\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"3.5%\", pad=0.3, axes_class=plt.Axes)\n",
    "fig.colorbar(pcm, cax=cax, label=\"Rigidity [GV]\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf83f7af-2e32-40de-8554-9cdc463e8d50",
   "metadata": {},
   "source": [
    "Cutoff values are computed at discrete grid nodes.  \n",
    "In the next cell, the map is rendered with linear interpolation (`shading=\"gouraud\"`) to make the visualization smoother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b72302-e24d-4f80-9d11-c35ec761730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "pcm = ax.pcolormesh(lon_grid, lat_grid, r_grid, shading=\"gouraud\", vmin=0)\n",
    "ax.set_xlim(-180, 180)\n",
    "ax.set_ylim(-70, 70)\n",
    "ax.coastlines(resolution=\"110m\", linewidth=1.0, color=\"black\")\n",
    "\n",
    "ax.set_xticks(np.arange(-180, 181, 60))\n",
    "ax.set_yticks(np.arange(-60, 61, 20))\n",
    "ax.set_xlabel('Longitude [deg]')\n",
    "ax.set_ylabel('Latitude [deg]')\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"3.5%\", pad=0.3, axes_class=plt.Axes)\n",
    "fig.colorbar(pcm, cax=cax, label=\"Rigidity [GV]\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d294596-0cfa-4902-a01c-2a5205cfc984",
   "metadata": {},
   "source": [
    "# Refined map: local scan around the coarse estimate\n",
    "\n",
    "This refinement step re-computes `R_eff` using a finer rigidity step, but only within a narrow interval around the coarse estimate (±1 GV for each grid point).\n",
    "This approach preserves most of the accuracy benefits while keeping the total runtime manageable.\n",
    "\n",
    "As before, the computation is parallelized over grid points.\n",
    "Expected output: a refined global map of `R_eff` with improved resolution compared to the coarse scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40059a98-d83e-4e5e-90b1-00aa284df78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the 180° meridian to save computation time\n",
    "lon_grid = lon_grid[:-1]\n",
    "r_grid = r_grid[:, :-1]\n",
    "\n",
    "# copy the previously obtained coarse map\n",
    "r_grid_base = r_grid.copy()\n",
    "r_grid = np.zeros_like(r_grid_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e963ee28-deb3-40f4-9d6a-db94d502abd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def worker(i_lon, i_lat):\n",
    "    rigidity_array = np.arange(r_grid_base[i_lat, i_lon] - 1,\n",
    "                               r_grid_base[i_lat, i_lon] + 1.01, 0.02)\n",
    "    rigidity_array = rigidity_array[rigidity_array > 0.001]\n",
    "    barcode = get_vertical_barcode(lon_grid[i_lon], lat_grid[i_lat], 400, rigidity_array)\n",
    "    _, r_eff, _ = get_penumbra_parameters(rigidity_array, barcode)\n",
    "    return i_lon, i_lat, r_eff\n",
    "\n",
    "with tqdm_joblib(total=len(tasks)):\n",
    "    res = Parallel(n_jobs=-1)(delayed(worker)(i, j) for i, j in tasks)\n",
    "for i_lon, i_lat, v in res:\n",
    "    r_grid[i_lat, i_lon] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c787b6e-cc31-466c-aa19-ec56801ebebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the 180° meridian and copy values from the -180° meridian in order to stitch the map seamlessly\n",
    "lon_grid = np.hstack((lon_grid, 180))\n",
    "r_grid = np.pad(r_grid, pad_width=((0, 0), (0, 1)), mode=\"wrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f02aa93-761d-419b-977c-aa0ffd046917",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "pcm = ax.pcolormesh(lon_grid, lat_grid, r_grid, vmin=0)\n",
    "ax.set_xlim(-180, 180)\n",
    "ax.set_ylim(-70, 70)\n",
    "ax.coastlines(resolution=\"110m\", linewidth=1.0, color=\"black\")\n",
    "\n",
    "ax.set_xticks(np.arange(-180, 181, 60))\n",
    "ax.set_yticks(np.arange(-60, 61, 20))\n",
    "ax.set_xlabel('Longitude [deg]')\n",
    "ax.set_ylabel('Latitude [deg]')\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"3.5%\", pad=0.3, axes_class=plt.Axes)\n",
    "fig.colorbar(pcm, cax=cax, label=\"Rigidity [GV]\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390aa634-b843-4ed0-ac25-689a7c6e056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "pcm = ax.pcolormesh(lon_grid, lat_grid, r_grid, shading=\"gouraud\", vmin=0)\n",
    "ax.set_xlim(-180, 180)\n",
    "ax.set_ylim(-70, 70)\n",
    "ax.coastlines(resolution=\"110m\", linewidth=1.0, color=\"black\")\n",
    "\n",
    "ax.set_xticks(np.arange(-180, 181, 60))\n",
    "ax.set_yticks(np.arange(-60, 61, 20))\n",
    "ax.set_xlabel('Longitude [deg]')\n",
    "ax.set_ylabel('Latitude [deg]')\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"3.5%\", pad=0.2, axes_class=plt.Axes)\n",
    "fig.colorbar(pcm, cax=cax, label=\"Rigidity [GV]\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c59d3c1-3950-401d-becc-39779015a146",
   "metadata": {},
   "source": [
    "Potential ways to improve accuracy and resolve finer penumbra structure:\n",
    "- Decrease the integration time step (e.g., down to 1e-6 s).\n",
    "- Use a finer rigidity step (e.g., 0.001 GV) in the barcode scan.\n",
    "- Increase the latitude/longitude grid resolution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (GTsimulation)",
   "language": "python",
   "name": "gtsimkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
